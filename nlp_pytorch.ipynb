{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc028762710>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import seaborn as sns\n",
    "\n",
    "corpus = ['Time flies like an arrow.', 'Fruit flies like a banana.']\n",
    "onehot_vectorizer = CountVectorizer(binary=True)\n",
    "onehot = onehot_vectorizer.fit_transform(corpus).toarray()\n",
    "vocab = onehot_vectorizer.vocabulary_\n",
    "sns.heatmap(onehot, annot=True, cbar=False, xticklabels=vocab, yticklabels=['Sentence 2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc0266b8a90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf = tfidf_vectorizer.fit_transform(corpus).toarray()\n",
    "\n",
    "sns.heatmap(tfidf, annot=True, cbar=False, xticklabels=vocab, yticklabels=['Sentence 2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "# tensor helper function\n",
    "def describe(x):\n",
    "    print('Type: {}'.format(x.type()))\n",
    "    print('Shape/size: {}'.format(x.shape))\n",
    "    print('Values: \\n{}'.format(x))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[1.3556e-19, 1.3563e-19, 1.3563e-19],\n",
      "        [7.9717e-10, 5.8270e-10, 5.9669e-07]])\n",
      "\n",
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[0.7604, 0.7933, 0.0379],\n",
      "        [0.7701, 0.5665, 0.8742]])\n",
      "\n",
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[ 1.1839, -0.3516, -1.3866],\n",
      "        [-0.0543, -1.8330, -1.1297]])\n",
      "\n",
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "\n",
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "\n",
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[5., 5., 5.],\n",
      "        [5., 5., 5.]])\n",
      "\n",
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "\n",
      "Type: torch.DoubleTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[0.8399, 0.2803, 0.7386],\n",
      "        [0.1058, 0.7145, 0.5922]], dtype=torch.float64)\n",
      "\n",
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "\n",
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "describe(torch.Tensor(2, 3))\n",
    "describe(torch.rand(2, 3)) # uniform\n",
    "describe(torch.randn(2, 3)) # normal\n",
    "\n",
    "describe(torch.zeros(2, 3))\n",
    "x = torch.ones(2, 3)\n",
    "describe(x)\n",
    "x.fill_(5)\n",
    "describe(x)\n",
    "\n",
    "x = torch.Tensor([[1,2,3],[4,5,6]])\n",
    "describe(x)\n",
    "\n",
    "npy = np.random.rand(2, 3)\n",
    "describe(torch.from_numpy(npy))\n",
    "\n",
    "x = torch.FloatTensor([[1,2,3],[4,5,6]])\n",
    "describe(x)\n",
    "describe(x.long())\n",
    "\n",
    "x = torch.tensor([[1,2,3],[4,5,6]], dtype=torch.int64)\n",
    "describe(x)\n",
    "describe(x.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[0.7585, 0.4818, 0.2804],\n",
      "        [0.4033, 0.6010, 0.0588]])\n",
      "\n",
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[-1.6055, -1.4903, -0.8906],\n",
      "        [-1.5165, -1.0290,  1.5388]])\n",
      "\n",
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[1.5171, 0.9637, 0.5608],\n",
      "        [0.8066, 1.2019, 0.1176]])\n",
      "\n",
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[-0.8469, -1.0085, -0.6103],\n",
      "        [-1.1132, -0.4280,  1.5976]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2, 3)\n",
    "y = torch.randn(2, 3)\n",
    "describe(x)\n",
    "describe(y)\n",
    "describe(torch.add(x,x))\n",
    "describe(x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([6])\n",
      "Values: \n",
      "tensor([0, 1, 2, 3, 4, 5])\n",
      "\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([3])\n",
      "Values: \n",
      "tensor([3, 5, 7])\n",
      "\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([2])\n",
      "Values: \n",
      "tensor([ 3, 12])\n",
      "\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([6])\n",
      "Values: \n",
      "tensor([0, 1, 2, 3, 4, 5])\n",
      "\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([1, 2])\n",
      "Values: \n",
      "tensor([[0, 1]])\n",
      "\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([])\n",
      "Values: \n",
      "1\n",
      "\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([2, 2])\n",
      "Values: \n",
      "tensor([[0, 2],\n",
      "        [3, 5]])\n",
      "\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[0, 1, 2],\n",
      "        [0, 1, 2]])\n",
      "\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([2])\n",
      "Values: \n",
      "tensor([0, 1])\n",
      "\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([2])\n",
      "Values: \n",
      "tensor([0, 1])\n",
      "\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([2])\n",
      "Values: \n",
      "tensor([0, 4])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(6)\n",
    "describe(x)\n",
    "describe(x.view(2, 3))\n",
    "describe(torch.sum(x.view(2, 3), dim=0))\n",
    "describe(torch.sum(x.view(2, 3), dim=1))\n",
    "describe(torch.transpose(x, 0, -1))\n",
    "describe(torch.arange(6).view(2, 3)[:1, :2])\n",
    "describe(torch.arange(6).view(2, 3)[0, 1])\n",
    "\n",
    "# non-contiguous indexing use LongTensors everywhere\n",
    "indices = torch.LongTensor([0, 2])\n",
    "describe(torch.index_select(x.view(2, 3), dim=1, index=indices)) # columns 0 and 2\n",
    "indices = torch.LongTensor([0, 0])\n",
    "describe(torch.index_select(x.view(2, 3), dim=0, index=indices)) # row zero twice\n",
    "\n",
    "row_indices = torch.arange(2).long()\n",
    "col_indices = torch.LongTensor([0, 1])\n",
    "describe(row_indices)\n",
    "describe(col_indices)\n",
    "describe(x.view(2, 3)[row_indices, col_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([4, 3])\n",
      "Values: \n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([2, 6])\n",
      "Values: \n",
      "tensor([[0, 1, 2, 0, 1, 2],\n",
      "        [3, 4, 5, 3, 4, 5]])\n",
      "\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([2, 2, 3])\n",
      "Values: \n",
      "tensor([[[0, 1, 2],\n",
      "         [3, 4, 5]],\n",
      "\n",
      "        [[0, 1, 2],\n",
      "         [3, 4, 5]]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# concats and stacks\n",
    "x = torch.arange(6).view(2, 3)\n",
    "describe(torch.cat([x, x], dim=0))\n",
    "describe(torch.cat([x, x], dim=1))\n",
    "describe(torch.stack([x, x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[0., 1., 2.],\n",
      "        [3., 4., 5.]])\n",
      "\n",
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([3, 2])\n",
      "Values: \n",
      "tensor([[1., 2.],\n",
      "        [1., 2.],\n",
      "        [1., 2.]])\n",
      "\n",
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 2])\n",
      "Values: \n",
      "tensor([[ 3.,  6.],\n",
      "        [12., 24.]])\n",
      "\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([3, 2])\n",
      "Values: \n",
      "tensor([[1, 2],\n",
      "        [1, 2],\n",
      "        [1, 2]])\n",
      "\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([2, 2])\n",
      "Values: \n",
      "tensor([[ 3,  6],\n",
      "        [12, 24]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# note the implicit types for arange() and ones() differs\n",
    "x1 = torch.arange(6).view(2, 3).float() # shape M x N\n",
    "x2 = torch.ones([3, 2]) # shape N x P\n",
    "x2[:, 1] += 1 # all rows, col 1, in place\n",
    "describe(x1)\n",
    "describe(x2)\n",
    "describe(torch.mm(x1, x2)) # shape M x P\n",
    "\n",
    "x1 = torch.arange(6).view(2, 3) # shape M x N\n",
    "x2 = torch.ones([3, 2]).long() # shape N x P\n",
    "x2[:, 1] += 1 # all rows, col 1, in place\n",
    "describe(x1)\n",
    "describe(x2)\n",
    "describe(torch.mm(x1, x2)) # shape M x P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 2])\n",
      "Values: \n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "\n",
      "True\n",
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 2])\n",
      "Values: \n",
      "tensor([[21., 21.],\n",
      "        [21., 21.]], grad_fn=<AddBackward0>)\n",
      "\n",
      "True\n",
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([])\n",
      "Values: \n",
      "21.0\n",
      "\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# working with gradients\n",
    "x = torch.ones(2,2, requires_grad=True)\n",
    "describe(x)\n",
    "print(x.grad is None)\n",
    "\n",
    "y = (x + 2) * (x + 5) + 3\n",
    "describe(y)\n",
    "print(x.grad is None)\n",
    "\n",
    "z = y.mean()\n",
    "describe(z)\n",
    "z.backward()\n",
    "print(x.grad is None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "cuda\n",
      "Type: torch.cuda.FloatTensor\n",
      "Shape/size: torch.Size([3, 3])\n",
      "Values: \n",
      "tensor([[0.7077, 0.7679, 0.5796],\n",
      "        [0.8835, 0.3764, 0.1478],\n",
      "        [0.4507, 0.9879, 0.7085]], device='cuda:0')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "x = torch.rand(3, 3).to(device)\n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7080, 0.9074, 0.5476],\n",
      "        [0.1013, 0.2554, 0.5676],\n",
      "        [0.5564, 0.9101, 0.5677]])\n",
      "tensor([[0.7080, 0.9074, 0.5476],\n",
      "        [0.1013, 0.2554, 0.5676],\n",
      "        [0.5564, 0.9101, 0.5677]])\n",
      "tensor([[3.5415, 2.8557, 4.6126, 4.6102, 4.5397, 4.5750, 3.5977]])\n",
      "tensor([[4.6957, 4.4824, 3.7058, 3.4853, 2.7755, 3.2758, 4.1569]])\n",
      "tensor(-0.5636)\n",
      "tensor([[0],\n",
      "        [1],\n",
      "        [3]])\n",
      "tensor([[[-0.8614],\n",
      "         [ 1.1338],\n",
      "         [ 0.8174]],\n",
      "\n",
      "        [[-0.8614],\n",
      "         [ 1.1338],\n",
      "         [ 0.8174]],\n",
      "\n",
      "        [[-0.8614],\n",
      "         [ 1.1338],\n",
      "         [ 0.8174]],\n",
      "\n",
      "        [[-0.8614],\n",
      "         [ 1.1338],\n",
      "         [ 0.8174]]])\n",
      "tensor([[-0.8614, -0.8614, -0.8614, -0.8614],\n",
      "        [ 1.1338,  1.1338,  1.1338,  1.1338],\n",
      "        [ 0.8174,  0.8174,  0.8174,  0.8174]])\n",
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([3, 4, 4])\n",
      "Values: \n",
      "tensor([[[0.5751, 0.7646, 0.6524, 0.2233],\n",
      "         [0.8636, 0.9205, 1.0302, 0.3486],\n",
      "         [0.8396, 0.6914, 0.7920, 0.7777],\n",
      "         [1.0525, 1.5602, 1.3906, 0.4508]],\n",
      "\n",
      "        [[0.7214, 2.4148, 2.3186, 1.1706],\n",
      "         [1.0571, 2.6710, 2.5699, 1.4370],\n",
      "         [0.7184, 1.6674, 1.4809, 1.0310],\n",
      "         [0.8695, 2.3955, 2.5739, 1.1960]],\n",
      "\n",
      "        [[1.2937, 2.0498, 1.5888, 1.2447],\n",
      "         [0.8241, 1.4042, 1.1933, 0.9893],\n",
      "         [0.5295, 0.9523, 0.6888, 0.5749],\n",
      "         [0.5582, 1.1895, 0.8677, 0.5881]]])\n",
      "\n",
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([3, 4, 4])\n",
      "Values: \n",
      "tensor([[[1.0008, 0.6421, 1.3148, 1.6832],\n",
      "         [1.3689, 1.0762, 1.5188, 1.5383],\n",
      "         [1.9766, 1.6678, 1.9957, 2.3359],\n",
      "         [1.7128, 1.6747, 1.7575, 2.4377]],\n",
      "\n",
      "        [[1.2030, 1.0806, 1.1436, 2.0798],\n",
      "         [1.4428, 1.3709, 1.6076, 2.0018],\n",
      "         [0.8010, 0.7735, 0.8655, 1.2995],\n",
      "         [1.0741, 0.9769, 1.1666, 0.7531]],\n",
      "\n",
      "        [[0.9373, 0.5337, 1.1908, 1.7594],\n",
      "         [1.2269, 1.3871, 1.0922, 1.7458],\n",
      "         [1.6487, 1.5572, 1.5692, 1.9469],\n",
      "         [1.3487, 1.3039, 1.4202, 1.5665]]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(3, 3)\n",
    "x.unsqueeze(1) # ??\n",
    "print(x)\n",
    "x.squeeze(1)\n",
    "print(x)\n",
    "r1 = 2 # Create uniform random numbers in half-open interval [2.0, 5.0)\n",
    "r2 = 5\n",
    "a = 1  # Create tensor shape 1 x 7\n",
    "b = 7\n",
    "# If U is a random variable uniformly distributed on [0, 1],\n",
    "# then (r1 - r2) * U + r2 is uniformly distributed on [r1, r2]\n",
    "x = torch.rand(a, b)\n",
    "print((r2 - r1) * x + r1)\n",
    "\n",
    "x = torch.FloatTensor(a, b).uniform_(r1, r2) # easier tho\n",
    "print(x)\n",
    "\n",
    "x = torch.randn(3, 3)\n",
    "print(x.mean())\n",
    "print(torch.Tensor([1, 1, 0, 1]).nonzero())\n",
    "\n",
    "x = torch.randn(3, 1)\n",
    "print(torch.stack([x, x, x, x]))\n",
    "print(x.expand(3, 4))\n",
    "\n",
    "x = torch.rand(3, 4, 5)\n",
    "y = torch.rand(3, 5, 4)\n",
    "describe(torch.bmm(x, y))\n",
    "\n",
    "x = torch.rand(3, 4, 5)\n",
    "y = torch.rand(5, 4)\n",
    "describe(torch.bmm(x, y.unsqueeze(0).expand(x.size(0), *y.size())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.8081, 0.3212, 0.5950, 0.3762],\n",
       "         [0.8721, 0.4895, 0.6368, 0.7434],\n",
       "         [0.8731, 0.0275, 0.2132, 0.1630],\n",
       "         [0.6446, 0.4910, 0.7307, 0.4377],\n",
       "         [0.8647, 0.6589, 0.5963, 0.5936]],\n",
       "\n",
       "        [[0.8081, 0.3212, 0.5950, 0.3762],\n",
       "         [0.8721, 0.4895, 0.6368, 0.7434],\n",
       "         [0.8731, 0.0275, 0.2132, 0.1630],\n",
       "         [0.6446, 0.4910, 0.7307, 0.4377],\n",
       "         [0.8647, 0.6589, 0.5963, 0.5936]],\n",
       "\n",
       "        [[0.8081, 0.3212, 0.5950, 0.3762],\n",
       "         [0.8721, 0.4895, 0.6368, 0.7434],\n",
       "         [0.8731, 0.0275, 0.2132, 0.1630],\n",
       "         [0.6446, 0.4910, 0.7307, 0.4377],\n",
       "         [0.8647, 0.6589, 0.5963, 0.5936]]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unsqueeze(0).expand(x.size(0), *y.size())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
